{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Output Generation\n",
    "\n",
    "> Fill in a module description here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp Output_Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import os\n",
    "import nbdev\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from google.cloud import vision\n",
    "import io\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def data_concat(scan_text):\n",
    "    # This function aims to concat prompt and user's problem\n",
    "    # input: (user's problem, string type)\n",
    "    # process: string concat\n",
    "    # output: question to send to the Chatgpt\n",
    "    prompt =  \"\"\"\n",
    "    Assist with Mathematical Problems: Your primary goal is to help users solve math problems. You use a structured approach that emphasizes clarity and step-by-step explanations. \n",
    "    Use language for Explanations: All explanations are provided in plain language to ensure they are understandable and accessible. \n",
    "    Avoidance of Programming for Calculations: Unlike some other models that may use programming languages like Python for calculations, You are instructed to rely solely on mathematical principles and reasoning for solving problems.\n",
    "    Integrate Theories or Specific Methods: If a user provides a specific theory or method they want to use, you'll incorporate it into the problem-solving process.\n",
    "    Organize Responses for Easy Understanding: Your responses are organized meticulously to facilitate ease of understanding and learning.\n",
    "    Here is how your answers are organized:\n",
    "    1 - Start by clearly defining the problem or concept on your own, and completely understand it (without telling the user).\n",
    "    2 - If the solution is correct, just say “Correct” and end the conversation. If not, continue:\n",
    "    2.1 - Identify Key Concepts: Highlight the core mathematical principles or formulas that are relevant to solving the problem or understanding the concept.\n",
    "    2.2 - Identify the weakness of the solution: Identify which part of the solution is incorrect and tell me, without giving the solution. Ask me if I want to continue afterwards, stop if not.\n",
    "    3 - Step-by-Step Solution: If I say yes, provide a straightforward, step-by-step approach to solve the problem, including only essential steps and reasoning.\n",
    "    4 - Quick guidance: Present further links for me to learn about the relevant topic. Keep it short, ensuring it directly addresses the question.\n",
    "    Handling Non-Math Queries: When presented with a question outside your expertise, you won't answer directly but will offer a funny (yet not cheesy) reply that aims to satisfy the user's curiosity in a light-hearted way.\n",
    "    Handling Problems with No Solution: In cases where there's no solution to a problem, you'll walk the user through the problem, offering hints on potential starting points. You'll make it clear that while a solution isn't available, there's value in exploring the problem from these angles.\n",
    "    Your guidance remains concise and to the point.\n",
    "    \"\"\"\n",
    "    scan_text_prompt = prompt + scan_text\n",
    "    return scan_text_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def generate_output(scan_text_prompt, Chatgpt_key, model='gpt-4'):\n",
    "    # This function aims to calling Chatgpt API key and get mathematical answers\n",
    "    # input: (concated prompt, string type)\n",
    "    # process: string concat\n",
    "    # output: question to send to the Chatgpt\n",
    "\n",
    "    # Instantiate the OpenAI client with the API key.\n",
    "    client = openai.OpenAI(api_key = Chatgpt_key)\n",
    "    \n",
    "    try:\n",
    "        # Make the API call to OpenAI for generating predictions.\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": scan_text_prompt\n",
    "                }\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        full_response = response.choices[0].message.content\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any errors that occur during the API call.\n",
    "        print(f\"An error occurred while calling OpenAI API: {e}\")\n",
    "\n",
    "    return full_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def continue_prompt(latex_output,global_output):\n",
    "    continue_prompt_text = \"This is my prior input:\" + latex_output \n",
    "    continue_prompt_text = continue_prompt_text+ \"This is your prior output:\" \n",
    "    continue_prompt_text = continue_prompt_text + global_output \n",
    "    continue_prompt_text = continue_prompt_text + \"I don't quite understand it. Could you explain more?\"\n",
    "    return continue_prompt_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def m4th_assistant():\n",
    "    \n",
    "    Chatgpt_key = \"\"\n",
    "    \n",
    "    latex_output = None\n",
    "    global_output = None\n",
    "    global_scan_text_prompt = None\n",
    "\n",
    "\n",
    "    # Define the function for converting image to text using Google Cloud Vision\n",
    "    def convert_img_to_text(file_input):\n",
    "        nonlocal latex_output\n",
    "        client = vision.ImageAnnotatorClient()\n",
    "\n",
    "        with io.open(file_input.name, 'rb') as image_file:\n",
    "            content = image_file.read()\n",
    "\n",
    "        image = vision.Image(content=content)\n",
    "\n",
    "        response = client.document_text_detection(image=image)\n",
    "        document = response.full_text_annotation\n",
    "        latex_output = document.text\n",
    "        return latex_output\n",
    "            \n",
    "    # concat prompt & user's question\n",
    "    # show the output on the board\n",
    "    def output_generation():\n",
    "        nonlocal latex_output, global_output, global_scan_text_prompt\n",
    "\n",
    "        global_scan_text_prompt = data_concat(latex_output)\n",
    "        global_output = generate_output(global_scan_text_prompt, Chatgpt_key)\n",
    "\n",
    "        return global_output\n",
    "    \n",
    "    # concat history data & prompt\n",
    "    # show the data on the board\n",
    "    def continue_exploring():\n",
    "        nonlocal latex_output, global_output, global_scan_text_prompt\n",
    "\n",
    "        continue_prompt_text = continue_prompt(latex_output,global_output)\n",
    "        cotinue_output = generate_output(continue_prompt_text,Chatgpt_key)\n",
    "\n",
    "        latex_output = continue_prompt_text\n",
    "        continue_prompt_text = cotinue_output\n",
    "\n",
    "        return cotinue_output\n",
    "    \n",
    "    # clear all\n",
    "    def memory_initial():\n",
    "        nonlocal latex_output, global_output, global_scan_text_prompt\n",
    "\n",
    "        latex_output = None\n",
    "        global_output = None\n",
    "        global_scan_text_prompt = None\n",
    "\n",
    "        return \"\"\n",
    "    \n",
    "    return convert_img_to_text,output_generation,continue_exploring,memory_initial"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
